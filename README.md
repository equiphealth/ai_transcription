## Patient Transcript Evaluation Pipeline
This repository contains a pipeline designed to process patient transcripts, evaluate the correctness and conciseness of summaries generated by a GPT-based language model, and store the results in an S3 bucket for further analysis.

## Description
The pipeline performs the following main tasks:

## Load Configuration: Configuration settings are loaded from a YAML file (config.yml).
- Read Transcripts: Transcripts are read from a specified folder and processed.
- Fetch Data: Additional data (such as metadata and Zoom meeting data) is fetched based on patient information.
- Generate Summary: A prompt is generated for the language model (GPT-4) to summarize the transcript.
- Evaluate Summary: The generated summary is evaluated for correctness and conciseness using custom evaluation metrics.
- Store Results: The processed data and evaluation results are stored in an S3 bucket.

## Requirements
The following libraries are required to run the pipeline:

- awswrangler (for interacting with AWS S3)
- deepeval (for LLM evaluation)
- pandas (for data manipulation)
- yaml (for configuration parsing)
- time (for timing evaluations)

## You can install the dependencies by running:

```
pip install awswrangler deepeval pandas pyyaml
```

## Configuration
The pipeline requires a config.yml file to configure various settings:

- zoomdata_usage: Whether to use Zoom data for additional context.
- metadata_usage: Whether to use patient metadata.
- dev: A flag for development mode (used for local testing).
- bucket: S3 bucket configurations for storing the processed data and results.

## How It Works
- Load YAML Configuration: The configuration file is loaded into a dictionary and used throughout the pipeline to control behavior, including whether to use metadata and Zoom data.
- Transcript Processing: Each transcript is processed sequentially. The relevant metadata and Zoom meeting data are fetched using patient identifiers. These records are then passed into a prompt generator for the language model.
- Summary Generation: A summary of the transcript is generated by the GPT-4 model using a pre-defined prompt.
- Evaluation: The generated summary is evaluated using two primary metrics:
  - Correctness: Verifies if the summary is factually correct and aligned with the transcript.
  - Conciseness: Assesses whether the summary is succinct without losing key information, and maintains an objective tone.
- Results Storage: The final processed data (including the evaluation results) is uploaded to S3 for further use and analysis.

## Running the Script
To run the pipeline, simply execute the script:
```
python ai_transcripts.py
```
This will initiate the process of loading the transcripts, generating summaries, evaluating the summaries, and uploading the results to S3.
